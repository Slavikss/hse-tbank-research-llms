common:
  env_id: CartPole-v1
  gamma: 0.99
  lr_policy: 0.0003
  lr_value: 0.001
  hidden_sizes: [32, 32]
  trajectories_per_update: 4
  num_updates: 8
  max_steps_per_episode: 200
  normalize_advantage: true
  grad_clip_norm: 0.5
  eval_every: 2
  eval_episodes: 5
  early_stop_reward: 195.0
  moving_avg_alpha: 0.05
  device: cpu
  output_dir: artifacts/rl
  max_train_steps: 15000

seeds: [0]

experiments:
  - name: vpg
    baseline: none
    entropy_beta: 0.0
    entropy_beta_end: 0.0
    entropy_schedule: constant

  - name: vpg_value
    baseline: value
    entropy_beta: 0.001
    entropy_beta_end: 0.0
    entropy_schedule: linear
